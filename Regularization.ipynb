{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "We learned earlier that neural networks model correlation. Hidden layers in fact, create 'intermediate' correlation. However, how do we know that our networks are creating 'good' correlation? \n",
    "\n",
    "We experimented with Stochastic Gradient Descent by freezing one of the weights and then continued training on our neural network. Gradient Descent still found the local minima and climbed down the hill to lower ground by adjusting the rest of the weights to minimize the error. \n",
    "\n",
    "However, in most cases it will not be that Gradient Descent will help us climb down to the local minima which is the most optimal, instead Gradient Descent will help us find some other local minima so that the frozen weight value becomes optimal. Furthermore, if we unfroze the weight afterwards to do some more training, it wouldnt learn! That's because the error had already fallen to 0 and according to our network, there is nothing more to learn.\n",
    "\n",
    "This should make us think: what if the frozen weight was actually of paramount importance in helping us make predictions on real world data? We wouldve essentially trained a neural network which minimzed the error but was actually useless in the real world.\n",
    "\n",
    "This is an extremely common phenomena in neural networks and is known as **Overfitting**. The more powerful the neural network's expressive layers, the more prone the network is to overfitting. There's an everlasting battle going on in research where people continuously find tasks that need more powerful layers, but then find themselves in hard struggle to solve the problem of overfitting.\n",
    "\n",
    "Regularization is one very important solution to the problem of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/envs/jupiter/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at a training example [matrix]\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examining the image itself\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training purposes in our neural network, we must convert these image matrices of (28,28) dimensions into vectors of (1, 28x28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing reshaping the images\n",
    "X_train[0].reshape(1,28*28).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will also divide the image matrices by 255 in order to normalize the pixel values. A pixel is commonly stored as an 8-bit integer which has a range of possible values from 0-255. We'll do the transform for the whole dataset at a large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1000, 784) | X_test shape: (10000, 784)\n",
      "y_train shape: (1000,) | y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = (X_train[:1000].reshape(1000,28*28)/255, y_train[:1000])\n",
    "test_images, test_labels = (X_test.reshape(len(X_test),28*28)/255, y_test)\n",
    "print(f\"X_train shape: {train_images.shape} | X_test shape: {test_images.shape}\")\n",
    "print(f\"y_train shape: {train_labels.shape} | y_test shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(train_labels), 10)) # since there are 10 possible values\n",
    "for idx, label in enumerate(train_labels):\n",
    "    one_hot_labels[idx][label] = 1\n",
    "print(one_hot_labels.shape)\n",
    "train_labels = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(test_labels), 10)) # since there are 10 possible values\n",
    "for idx, label in enumerate(test_labels):\n",
    "    one_hot_labels[idx][label] = 1\n",
    "print(one_hot_labels.shape)\n",
    "test_labels = one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1) # for reproducibility purposes\n",
    "\n",
    "# defining the activation function (ReLU)\n",
    "relu = lambda x: (x>=0) * x # returns x if x > 0, 0 otherwise\n",
    "relu_d = lambda x:  x>=0 # returns 1 for x > 0, returns 0 otherwise\n",
    "\n",
    "alpha = 0.005 # learning rate\n",
    "epochs = 350\n",
    "hidden_size = 40\n",
    "pixels_per_image = 784\n",
    "num_labels = 10\n",
    "\n",
    "# initializing the weights\n",
    "\n",
    "# first layer of weights\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size))-0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels))-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:349 Train-Err:0.108 Train-Acc:0.998"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # intializing empty error variables\n",
    "    error, correct_count = (0.0, 0)\n",
    "    \n",
    "    # iterating through the images\n",
    "    for image in range(len(train_images)):\n",
    "        # first layer is just the image data\n",
    "        layer_0 = train_images[image:image+1]\n",
    "        # second layer is the dot product of the image and weights layer\n",
    "        # put through the activation function\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        # last layer is the output layer and is the dot product\n",
    "        # of the hidden layer and the last set of weights\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        # cost function\n",
    "        error += np.sum((train_labels[image:image+1] - layer_2)**2)\n",
    "        # how many correct we've gotten so far\n",
    "        correct_count += int(np.argmax(layer_2) == np.argmax(train_labels[image:image+1]))\n",
    "        \n",
    "        # backpropogation\n",
    "        # output to layer 2\n",
    "        layer_2_delta = (train_labels[image:image+1] - layer_2)\n",
    "        # layer 2 to layer 1\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu_d(layer_1)\n",
    "        \n",
    "        # updating the weights\n",
    "        # updating weights_1_2\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        # updating weights_0_1\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    sys.stdout.write(\"\\r I:\"+str(epoch)+ \\\n",
    "                 \" Train-Err:\" + str(error/float(len(train_images)))[0:5] +\\\n",
    "                 \" Train-Acc:\" + str(correct_count/float(len(train_images))))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:0.671 Test-Acc:0.7019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(epoch % 10 == 0 or epoch == epochs-1):\n",
    "    error, correct_count = (0.0, 0)\n",
    "\n",
    "    for image in range(len(test_images)):\n",
    "\n",
    "        layer_0 = test_images[image:image+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((test_labels[image:image+1] - layer_2) ** 2)\n",
    "        correct_count += int(np.argmax(layer_2) == \\\n",
    "                                        np.argmax(test_labels[image:image+1]))\n",
    "    sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "                     \" Test-Acc:\" + str(correct_count/float(len(test_images))) + \"\\n\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see here that our neural network performed phenomenally but had a rather lackluster performance on the test dataset. This is because our neural network grossly overfit our training data. What this means is that the neural network learned the variance in the data a bit _too_ well.\n",
    "\n",
    "Intuitively, you can think about it that if you're learning how to drive on a particular road, rather than understand when to put the break, when to accelerate, when to shift gears, you just memorize every action you your instructor tells you take on that road based on the timestamp. So if in your first try your instructor had told you to put the break 1 minute into driving on that road, you've memorized to use the break after 1 minute of driving. You'll do really well on that road because you've memorized the instruction of how to drive _on that road_ and on that road _alone_. You'll get your license taken away on any other road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "One of the industry standards for regularization in deep learning is dropout. It involves randomly switching off neurons during the training process. The effect this has is that it forces other neurons to compensate and learn some other features as well while preventing the turned off neurons to learn their features a bit too much. Neurons in a large neural network are likely to overfit to noise, however, it is unlikely for them to overfit to the same noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.718 Test-Acc:0.5418 Train-Err:0.885 Train-Acc:0.289\n",
      "I:10 Test-Err:0.501 Test-Acc:0.7365 Train-Err:0.564 Train-Acc:0.647\n",
      "I:20 Test-Err:0.478 Test-Acc:0.7621 Train-Err:0.530 Train-Acc:0.681\n",
      "I:30 Test-Err:0.457 Test-Acc:0.7915 Train-Err:0.508 Train-Acc:0.71\n",
      "I:40 Test-Err:0.445 Test-Acc:0.7998 Train-Err:0.492 Train-Acc:0.719\n",
      "I:50 Test-Err:0.430 Test-Acc:0.8145 Train-Err:0.462 Train-Acc:0.742\n",
      "I:60 Test-Err:0.446 Test-Acc:0.7974 Train-Err:0.472 Train-Acc:0.746\n",
      "I:70 Test-Err:0.445 Test-Acc:0.7901 Train-Err:0.463 Train-Acc:0.744\n",
      "I:80 Test-Err:0.426 Test-Acc:0.8105 Train-Err:0.461 Train-Acc:0.764\n",
      "I:90 Test-Err:0.435 Test-Acc:0.7871 Train-Err:0.462 Train-Acc:0.749\n",
      "I:100 Test-Err:0.433 Test-Acc:0.8039 Train-Err:0.452 Train-Acc:0.769\n",
      "I:110 Test-Err:0.435 Test-Acc:0.8099 Train-Err:0.439 Train-Acc:0.778\n",
      "I:120 Test-Err:0.442 Test-Acc:0.7871 Train-Err:0.451 Train-Acc:0.778\n",
      "I:130 Test-Err:0.439 Test-Acc:0.811 Train-Err:0.452 Train-Acc:0.783\n",
      "I:140 Test-Err:0.443 Test-Acc:0.8049 Train-Err:0.445 Train-Acc:0.779\n",
      "I:150 Test-Err:0.446 Test-Acc:0.7918 Train-Err:0.457 Train-Acc:0.783\n",
      "I:160 Test-Err:0.437 Test-Acc:0.81 Train-Err:0.456 Train-Acc:0.774\n",
      "I:170 Test-Err:0.430 Test-Acc:0.7963 Train-Err:0.439 Train-Acc:0.801\n",
      "I:180 Test-Err:0.432 Test-Acc:0.7955 Train-Err:0.453 Train-Acc:0.782\n",
      "I:190 Test-Err:0.436 Test-Acc:0.7997 Train-Err:0.433 Train-Acc:0.784\n",
      "I:200 Test-Err:0.436 Test-Acc:0.803 Train-Err:0.442 Train-Acc:0.796\n",
      "I:210 Test-Err:0.434 Test-Acc:0.8031 Train-Err:0.441 Train-Acc:0.79\n",
      "I:220 Test-Err:0.426 Test-Acc:0.8102 Train-Err:0.434 Train-Acc:0.777\n",
      "I:230 Test-Err:0.429 Test-Acc:0.8058 Train-Err:0.431 Train-Acc:0.803\n",
      "I:240 Test-Err:0.436 Test-Acc:0.8055 Train-Err:0.430 Train-Acc:0.788\n",
      "I:250 Test-Err:0.421 Test-Acc:0.8053 Train-Err:0.433 Train-Acc:0.789\n",
      "I:260 Test-Err:0.422 Test-Acc:0.8102 Train-Err:0.422 Train-Acc:0.79\n",
      "I:270 Test-Err:0.438 Test-Acc:0.8062 Train-Err:0.430 Train-Acc:0.803\n",
      "I:280 Test-Err:0.431 Test-Acc:0.7991 Train-Err:0.425 Train-Acc:0.79\n",
      "I:290 Test-Err:0.433 Test-Acc:0.8028 Train-Err:0.428 Train-Acc:0.792\n",
      "I:300 Test-Err:0.434 Test-Acc:0.7949 Train-Err:0.407 Train-Acc:0.804\n",
      "I:310 Test-Err:0.428 Test-Acc:0.8036 Train-Err:0.415 Train-Acc:0.793\n",
      "I:320 Test-Err:0.436 Test-Acc:0.8008 Train-Err:0.415 Train-Acc:0.812\n",
      "I:330 Test-Err:0.419 Test-Acc:0.8134 Train-Err:0.418 Train-Acc:0.817\n",
      "I:340 Test-Err:0.431 Test-Acc:0.8012 Train-Err:0.408 Train-Acc:0.814\n",
      "I:350 Test-Err:0.426 Test-Acc:0.8141 Train-Err:0.418 Train-Acc:0.79\n",
      "I:360 Test-Err:0.415 Test-Acc:0.8089 Train-Err:0.417 Train-Acc:0.796\n",
      "I:370 Test-Err:0.417 Test-Acc:0.8009 Train-Err:0.401 Train-Acc:0.822\n",
      "I:380 Test-Err:0.439 Test-Acc:0.8061 Train-Err:0.395 Train-Acc:0.816\n",
      "I:390 Test-Err:0.439 Test-Acc:0.8097 Train-Err:0.395 Train-Acc:0.829\n",
      "I:400 Test-Err:0.426 Test-Acc:0.8004 Train-Err:0.386 Train-Acc:0.835\n",
      "I:410 Test-Err:0.434 Test-Acc:0.8038 Train-Err:0.406 Train-Acc:0.812\n",
      "I:420 Test-Err:0.429 Test-Acc:0.8018 Train-Err:0.402 Train-Acc:0.821\n",
      "I:430 Test-Err:0.417 Test-Acc:0.7983 Train-Err:0.392 Train-Acc:0.805\n",
      "I:440 Test-Err:0.438 Test-Acc:0.81 Train-Err:0.400 Train-Acc:0.825"
     ]
    }
   ],
   "source": [
    "epochs = 450\n",
    "hidden_size = 100\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # intializing empty error variables\n",
    "    error, correct_count = (0.0, 0)\n",
    "    \n",
    "    # iterating through the images\n",
    "    for image in range(len(train_images)):\n",
    "        # first layer is just the image data\n",
    "        layer_0 = train_images[image:image+1]\n",
    "        # second layer is the dot product of the image and weights layer\n",
    "        # put through the activation function\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        # implementing the dropout layer\n",
    "        # this creates a mask of size layer_1 with 0 or 1 values\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        # last layer is the output layer and is the dot product\n",
    "        # of the hidden layer and the last set of weights\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        # cost function\n",
    "        error += np.sum((train_labels[image:image+1] - layer_2)**2)\n",
    "        # how many correct we've gotten so far\n",
    "        correct_count += int(np.argmax(layer_2) == np.argmax(train_labels[image:image+1]))\n",
    "        \n",
    "        # backpropogation\n",
    "        # output to layer 2\n",
    "        layer_2_delta = (train_labels[image:image+1] - layer_2)\n",
    "        # layer 2 to layer 1\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu_d(layer_1)\n",
    "        # dropout mask derivative\n",
    "        layer_1_delta *= dropout_mask\n",
    "        \n",
    "        # updating the weights\n",
    "        # updating weights_1_2\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        # updating weights_0_1\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    if(epoch%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                         \"I:\" + str(epoch) + \\\n",
    "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
    "                         \" Train-Err:\" + str(error/ float(len(train_images)))[0:5] +\\\n",
    "                         \" Train-Acc:\" + str(correct_count/ float(len(train_images))))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.863 Test-Acc:0.2907 Train-Err:1.098 Train-Acc:0.136\n",
      "I:10 Test-Err:0.620 Test-Acc:0.6531 Train-Err:1.081 Train-Acc:0.554\n",
      "I:20 Test-Err:0.558 Test-Acc:0.694 Train-Err:1.188 Train-Acc:0.609\n",
      "I:30 Test-Err:0.529 Test-Acc:0.7165 Train-Err:1.209 Train-Acc:0.638\n",
      "I:40 Test-Err:0.515 Test-Acc:0.7374 Train-Err:1.230 Train-Acc:0.623\n",
      "I:50 Test-Err:0.504 Test-Acc:0.746 Train-Err:1.290 Train-Acc:0.651\n",
      "I:60 Test-Err:0.505 Test-Acc:0.7424 Train-Err:1.330 Train-Acc:0.672\n",
      "I:70 Test-Err:0.499 Test-Acc:0.7452 Train-Err:1.310 Train-Acc:0.655\n",
      "I:80 Test-Err:0.486 Test-Acc:0.7562 Train-Err:1.308 Train-Acc:0.682\n",
      "I:90 Test-Err:0.490 Test-Acc:0.7437 Train-Err:1.313 Train-Acc:0.663\n",
      "I:100 Test-Err:0.485 Test-Acc:0.75 Train-Err:1.319 Train-Acc:0.706\n",
      "I:110 Test-Err:0.474 Test-Acc:0.7597 Train-Err:1.370 Train-Acc:0.699\n",
      "I:120 Test-Err:0.479 Test-Acc:0.7557 Train-Err:1.352 Train-Acc:0.705\n",
      "I:130 Test-Err:0.474 Test-Acc:0.7609 Train-Err:1.356 Train-Acc:0.701\n",
      "I:140 Test-Err:0.459 Test-Acc:0.7716 Train-Err:1.367 Train-Acc:0.727\n",
      "I:150 Test-Err:0.468 Test-Acc:0.7676 Train-Err:1.369 Train-Acc:0.733\n",
      "I:160 Test-Err:0.462 Test-Acc:0.7739 Train-Err:1.390 Train-Acc:0.719\n",
      "I:170 Test-Err:0.456 Test-Acc:0.7801 Train-Err:1.361 Train-Acc:0.727\n",
      "I:180 Test-Err:0.458 Test-Acc:0.7817 Train-Err:1.348 Train-Acc:0.702\n",
      "I:190 Test-Err:0.458 Test-Acc:0.7785 Train-Err:1.380 Train-Acc:0.723\n",
      "I:200 Test-Err:0.459 Test-Acc:0.7895 Train-Err:1.397 Train-Acc:0.725\n",
      "I:210 Test-Err:0.450 Test-Acc:0.7906 Train-Err:1.357 Train-Acc:0.728\n",
      "I:220 Test-Err:0.447 Test-Acc:0.787 Train-Err:1.377 Train-Acc:0.744\n",
      "I:230 Test-Err:0.443 Test-Acc:0.7899 Train-Err:1.400 Train-Acc:0.726\n",
      "I:240 Test-Err:0.442 Test-Acc:0.7951 Train-Err:1.406 Train-Acc:0.737\n",
      "I:250 Test-Err:0.448 Test-Acc:0.7916 Train-Err:1.348 Train-Acc:0.704\n",
      "I:260 Test-Err:0.441 Test-Acc:0.7875 Train-Err:1.380 Train-Acc:0.751\n",
      "I:270 Test-Err:0.438 Test-Acc:0.7914 Train-Err:1.410 Train-Acc:0.738\n",
      "I:280 Test-Err:0.434 Test-Acc:0.7964 Train-Err:1.386 Train-Acc:0.742\n",
      "I:290 Test-Err:0.437 Test-Acc:0.7908 Train-Err:1.410 Train-Acc:0.731\n",
      "I:300 Test-Err:0.429 Test-Acc:0.7932 Train-Err:1.403 Train-Acc:0.757\n",
      "I:310 Test-Err:0.425 Test-Acc:0.7996 Train-Err:1.379 Train-Acc:0.749\n",
      "I:320 Test-Err:0.436 Test-Acc:0.7972 Train-Err:1.414 Train-Acc:0.746\n",
      "I:330 Test-Err:0.428 Test-Acc:0.7934 Train-Err:1.389 Train-Acc:0.746\n",
      "I:340 Test-Err:0.430 Test-Acc:0.8006 Train-Err:1.433 Train-Acc:0.758\n",
      "I:350 Test-Err:0.424 Test-Acc:0.7966 Train-Err:1.380 Train-Acc:0.744\n",
      "I:360 Test-Err:0.426 Test-Acc:0.7951 Train-Err:1.411 Train-Acc:0.74\n",
      "I:370 Test-Err:0.421 Test-Acc:0.7969 Train-Err:1.389 Train-Acc:0.757\n",
      "I:380 Test-Err:0.424 Test-Acc:0.7969 Train-Err:1.433 Train-Acc:0.759\n",
      "I:390 Test-Err:0.424 Test-Acc:0.7954 Train-Err:1.423 Train-Acc:0.767\n",
      "I:400 Test-Err:0.423 Test-Acc:0.7985 Train-Err:1.423 Train-Acc:0.763\n",
      "I:410 Test-Err:0.421 Test-Acc:0.796 Train-Err:1.401 Train-Acc:0.758\n",
      "I:420 Test-Err:0.429 Test-Acc:0.7972 Train-Err:1.427 Train-Acc:0.757\n",
      "I:430 Test-Err:0.420 Test-Acc:0.7998 Train-Err:1.376 Train-Acc:0.731\n",
      "I:440 Test-Err:0.419 Test-Acc:0.798 Train-Err:1.423 Train-Acc:0.757"
     ]
    }
   ],
   "source": [
    "epochs = 450\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "alpha = 0.001\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # intializing empty error variables\n",
    "    error, correct_count = (0.0, 0)\n",
    "    \n",
    "    # iterating through the images\n",
    "    for image in range(int(len(train_images)/batch_size)):\n",
    "        batch_start, batch_end = ((image*batch_size),((image+1)*batch_size))\n",
    "        # first layer is just the image data\n",
    "        layer_0 = train_images[batch_start:batch_end]\n",
    "        # second layer is the dot product of the image and weights layer\n",
    "        # put through the activation function\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        # implementing the dropout layer\n",
    "        # this creates a mask of size layer_1 with 0 or 1 values\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        # last layer is the output layer and is the dot product\n",
    "        # of the hidden layer and the last set of weights\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        \n",
    "        # cost function\n",
    "        error += np.sum((train_labels[image:image+1] - layer_2)**2)\n",
    "        for batch in range(batch_size):\n",
    "            # how many correct we've gotten so far\n",
    "            correct_count += int(np.argmax(layer_2[batch:batch+1]) == \n",
    "                                 np.argmax(train_labels[batch_start+batch:batch_start+batch+1]))\n",
    "\n",
    "            # backpropogation\n",
    "            # output to layer 2\n",
    "            layer_2_delta = (train_labels[batch_start:batch_end] - layer_2)/batch_size\n",
    "            # layer 2 to layer 1\n",
    "            layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu_d(layer_1)\n",
    "            # dropout mask derivative\n",
    "            layer_1_delta *= dropout_mask\n",
    "\n",
    "            # updating the weights\n",
    "            # updating weights_1_2\n",
    "            weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "            # updating weights_0_1\n",
    "            weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "        \n",
    "    if(epoch%10 == 0):\n",
    "        test_error = 0.0\n",
    "        test_correct_cnt = 0\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "\n",
    "            test_error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "\n",
    "        sys.stdout.write(\"\\n\" + \\\n",
    "                         \"I:\" + str(epoch) + \\\n",
    "                         \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
    "                         \" Train-Err:\" + str(error/ float(len(train_images)))[0:5] +\\\n",
    "                         \" Train-Acc:\" + str(correct_count/ float(len(train_images))))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
